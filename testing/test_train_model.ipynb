{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from google.colab import drive\r\n",
    "drive.mount('/content/gdrive/')"
   ],
   "outputs": [],
   "metadata": {
    "id": "OUdrKjcXDDmd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# MODIFY HERE TO YOUR PATH IN GOOGLE DRIVE\r\n",
    "%cd /content/gdrive/MyDrive/CryptoML"
   ],
   "outputs": [],
   "metadata": {
    "id": "9OO2fAyuDFRL"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import speck as sp\r\n",
    "import numpy as np\r\n",
    "from pickle import dump\r\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\r\n",
    "from tensorflow.keras.models import Model\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Input, Reshape, Permute, Add, Flatten, BatchNormalization, Activation\r\n",
    "from tensorflow.keras import backend as K\r\n",
    "from tensorflow.keras.regularizers import l2\r\n",
    "\r\n",
    "bs = 5000;\r\n",
    "dir = './models/'\r\n",
    "\r\n",
    "def cyclic_lr(num_epochs, high_lr, low_lr):\r\n",
    "  res = lambda i: low_lr + ((num_epochs-1) - i % num_epochs)/(num_epochs-1) * (high_lr - low_lr)\r\n",
    "  return res\r\n",
    "\r\n",
    "def make_checkpoint(datei):\r\n",
    "  assert datei[:9] == \"./models/\"\r\n",
    "  assert datei[-3:] == \".h5\"\r\n",
    "    \r\n",
    "  res = ModelCheckpoint(datei, monitor='val_loss', save_best_only = True)\r\n",
    "  return res\r\n",
    "\r\n",
    "# make residual tower of convolutional blocks\r\n",
    "def make_resnet(num_blocks=2, num_filters=32, num_outputs=1, d1=64, d2=64, word_size=16, ks=3, depth=5, reg_param=0.0001, final_activation='sigmoid'):\r\n",
    "  assert num_outputs == 1\r\n",
    "  assert num_blocks in [2,4]\r\n",
    "\r\n",
    "  # Input and preprocessing layers\r\n",
    "  inp = Input(shape=(num_blocks * word_size * 2))\r\n",
    "  rs = Reshape((2 * num_blocks, word_size))(inp)\r\n",
    "  perm = Permute((2,1))(rs)\r\n",
    "  \r\n",
    "  # add a single residual layer that will expand the data to num_filters channels\r\n",
    "  # this is a bit-sliced layer\r\n",
    "  conv0 = Conv1D(num_filters, kernel_size=1, padding='same', kernel_regularizer=l2(reg_param))(perm)\r\n",
    "  conv0 = BatchNormalization()(conv0)\r\n",
    "  conv0 = Activation('relu')(conv0)\r\n",
    "\r\n",
    "  # add residual blocks\r\n",
    "  shortcut = conv0\r\n",
    "  for _ in range(depth):\r\n",
    "    conv1 = Conv1D(num_filters, kernel_size=ks, padding='same', kernel_regularizer=l2(reg_param))(shortcut)\r\n",
    "    conv1 = BatchNormalization()(conv1)\r\n",
    "    conv1 = Activation('relu')(conv1)\r\n",
    "    conv2 = Conv1D(num_filters, kernel_size=ks, padding='same',kernel_regularizer=l2(reg_param))(conv1)\r\n",
    "    conv2 = BatchNormalization()(conv2)\r\n",
    "    conv2 = Activation('relu')(conv2)\r\n",
    "    shortcut = Add()([shortcut, conv2])\r\n",
    "\r\n",
    "  # add prediction head\r\n",
    "  flat1 = Flatten()(shortcut)\r\n",
    "  dense1 = Dense(d1,kernel_regularizer=l2(reg_param))(flat1)\r\n",
    "  dense1 = BatchNormalization()(dense1)\r\n",
    "  dense1 = Activation('relu')(dense1)\r\n",
    "  dense2 = Dense(d2, kernel_regularizer=l2(reg_param))(dense1)\r\n",
    "  dense2 = BatchNormalization()(dense2)\r\n",
    "  dense2 = Activation('relu')(dense2)\r\n",
    "  out = Dense(num_outputs, activation=final_activation, kernel_regularizer=l2(reg_param))(dense2)\r\n",
    "  model = Model(inputs=inp, outputs=out)\r\n",
    "\r\n",
    "  return model\r\n",
    "\r\n",
    "def train_speck_distinguisher(num_epochs, num_rounds=7, depth=1, num_blocks=2, diffa=(0x0040,0), diffb=(0x0020,0)):\r\n",
    "    assert num_epochs > 0\r\n",
    "    assert num_rounds > 0\r\n",
    "    assert depth > 0\r\n",
    "    assert num_blocks in [2, 4]\r\n",
    "    assert type(diffa) is tuple and type(diffb) is tuple\r\n",
    "\r\n",
    "    # create the network\r\n",
    "    net = make_resnet(num_blocks=num_blocks, depth=depth, reg_param=10**-5)\r\n",
    "    net.compile(optimizer='adam',loss='mse',metrics=['acc'])\r\n",
    "\r\n",
    "    # generate training and validation data\r\n",
    "    if num_blocks == 2:\r\n",
    "      X, Y = sp.make_train_data_2pt(10**7, num_rounds, diff=diffa)\r\n",
    "      X_eval, Y_eval = sp.make_train_data_2pt(10**6, num_rounds, diff=diffa)\r\n",
    "    \r\n",
    "    else:\r\n",
    "      X, Y = sp.make_train_data_4pt(10**7, num_rounds, diffa=diffa, diffb=diffb)\r\n",
    "      X_eval, Y_eval = sp.make_train_data_4pt(10**6, num_rounds, diffa=diffa, diffb=diffb)\r\n",
    "\r\n",
    "    # set up model checkpoint\r\n",
    "    check = make_checkpoint(dir+'best'+str(num_rounds)+'depth'+str(depth)+'.h5')\r\n",
    "\r\n",
    "    # create learnrate schedule\r\n",
    "    lr = LearningRateScheduler(cyclic_lr(10,0.002, 0.0001))\r\n",
    "\r\n",
    "    # train and evaluate\r\n",
    "    h = net.fit(X,Y,epochs=num_epochs,batch_size=bs,validation_data=(X_eval, Y_eval), callbacks=[lr,check])\r\n",
    "    np.save(dir+'h'+str(num_rounds)+'r_depth'+str(depth)+'.npy', h.history['val_acc'])\r\n",
    "    np.save(dir+'h'+str(num_rounds)+'r_depth'+str(depth)+'.npy', h.history['val_loss'])\r\n",
    "    dump(h.history,open(dir+'hist'+str(num_rounds)+'r_depth'+str(depth)+'.p','wb'))\r\n",
    "    print(\"Best validation accuracy: \", np.max(h.history['val_acc']))\r\n",
    "\r\n",
    "    return net, h"
   ],
   "outputs": [],
   "metadata": {
    "id": "fhpoMEFWXywa"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# MODIFY HERE: \r\n",
    "\r\n",
    "# number of epochs, number of Speck rounds, depth, number of plaintexts (2 or 4), bit difference #1, bit difference #2 (if 4 plaintexts)\r\n",
    "train_speck_distinguisher(1, num_rounds=5, depth=10, num_blocks=4, diffa=(0x0040,0), diffb=(0x0020,0))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TEST\r\n",
    "import unittest\r\n",
    "\r\n",
    "class TestTrainModelIPYNB(unittest.TestCase):\r\n",
    "    \r\n",
    "    def test_cyclic_lr(self):\r\n",
    "        \r\n",
    "        # Test cyclic_lr(10,0.002,0.0001)'s correctness and border cases\r\n",
    "        small_epochs = [1,5,9,10]\r\n",
    "        answer_small = [0.001788888888888889, 0.0009444444444444445, 0.0001, 0.002]\r\n",
    "        self.assertEqual(answer_small, list(map(cyclic_lr(10, 0.002, 0.0001), small_epochs)))\r\n",
    "        \r\n",
    "        big_epochs = [10,20,30,50,100,200,1000]\r\n",
    "        answer_big = [0.002 for _ in range(7)]\r\n",
    "        self.assertEqual(answer_big, list(map(cyclic_lr(10, 0.002, 0.0001), big_epochs)))\r\n",
    "        \r\n",
    "        # Test cyclic_lr(20,0.002,0.0001)'s correctness and border cases\r\n",
    "        num_epochs = [1,10,15,19,50,200]\r\n",
    "        answer = [0.0019, 0.001, 0.0005, 0.0001, 0.001, 0.002]\r\n",
    "        self.assertEqual(answer, list(map(cyclic_lr(20, 0.002, 0.0001), num_epochs)))\r\n",
    "        \r\n",
    "        # Test with num_epochs = 0 as parameter\r\n",
    "        with self.assertRaises(ZeroDivisionError):\r\n",
    "            list(map(cyclic_lr(0, 0.002, 0.0001), num_epochs))\r\n",
    "        \r\n",
    "    def test_make_checkpoint(self):\r\n",
    "        # Check if model is saving in ./models/\r\n",
    "        with self.assertRaises(AssertionError):\r\n",
    "            make_checkpoint(\"./model/best5depth10.h5\")\r\n",
    "        \r\n",
    "        # Check model in correct file format\r\n",
    "        with self.assertRaises(AssertionError):\r\n",
    "            make_checkpoint(\"./models/best5depth1.com\")\r\n",
    "        \r\n",
    "        # Able to save models with correct format\r\n",
    "        self.assertTrue(make_checkpoint(\"./models/best10depth10.h5\"))\r\n",
    "        self.assertTrue(make_checkpoint(\"./models/best6depth10.h5\"))\r\n",
    "        \r\n",
    "    def test_make_resnet(self):\r\n",
    "        \r\n",
    "        # Invalid num_blocks or num_outputs\r\n",
    "        with self.assertRaises(AssertionError):\r\n",
    "            make_resnet(num_blocks=1)\r\n",
    "            \r\n",
    "        with self.assertRaises(AssertionError):\r\n",
    "            make_resnet(num_outputs=2)\r\n",
    "            \r\n",
    "        with self.assertRaises(ValueError):\r\n",
    "            make_resnet(final_activation='wrong')\r\n",
    "        \r\n",
    "        # Check number of layers affected by depth\r\n",
    "        for i in range(10):\r\n",
    "            model = make_resnet(depth=i)\r\n",
    "            self.assertEqual(14+(i*7), len(model.layers))\r\n",
    "            \r\n",
    "        # Model used will be depth=1 \r\n",
    "        # (increasing in depth only increase number of loops in the same residual block I tested)\r\n",
    "        \r\n",
    "        # Check input_layer affected by num_blocks\r\n",
    "        model = make_resnet(num_blocks=2, depth=1)\r\n",
    "        self.assertEqual([(None,64)], model.layers[0].input_shape)\r\n",
    "        \r\n",
    "        model = make_resnet(num_blocks=4, depth=1)\r\n",
    "        self.assertEqual([(None,128)], model.layers[0].input_shape)\r\n",
    "        \r\n",
    "        # Check filters in the Conv1D layers\r\n",
    "        model = make_resnet(num_filters=32, depth=1)\r\n",
    "        self.assertEqual(32, model.layers[3].filters)\r\n",
    "        self.assertEqual(32, model.layers[6].filters)\r\n",
    "        self.assertEqual(32, model.layers[9].filters)\r\n",
    "        \r\n",
    "        # Check kernel size in the Conv1D layers\r\n",
    "        model = make_resnet(depth=1, ks=6)\r\n",
    "        self.assertEqual((1,), model.layers[3].kernel_size)\r\n",
    "        self.assertEqual((6,), model.layers[6].kernel_size)\r\n",
    "        self.assertEqual((6,), model.layers[9].kernel_size)\r\n",
    "        \r\n",
    "        model = make_resnet(depth=1, ks=3)\r\n",
    "        self.assertEqual((1,), model.layers[3].kernel_size)\r\n",
    "        self.assertEqual((3,), model.layers[6].kernel_size)\r\n",
    "        self.assertEqual((3,), model.layers[9].kernel_size)\r\n",
    "        \r\n",
    "        # Check units in Dense layers\r\n",
    "        model = make_resnet(depth=1, num_outputs=1, d1=64, d2=32)\r\n",
    "        self.assertEqual(64, model.layers[-7].units)\r\n",
    "        self.assertEqual(32, model.layers[-4].units)\r\n",
    "        self.assertEqual(1, model.layers[-1].units)\r\n",
    "        \r\n",
    "        model = make_resnet(depth=1, num_outputs=1, d1=64, d2=64)\r\n",
    "        self.assertEqual(64, model.layers[-7].units)\r\n",
    "        self.assertEqual(64, model.layers[-4].units)\r\n",
    "        self.assertEqual(1, model.layers[-1].units)\r\n",
    "        \r\n",
    "        \r\n",
    "        \r\n",
    "    def test_train_speck_distinguisher(self):\r\n",
    "        \r\n",
    "        # Didn't input num_epochs\r\n",
    "        with self.assertRaises(TypeError):\r\n",
    "            train_speck_distinguisher()\r\n",
    "        \r\n",
    "        # Invalid num_epochs\r\n",
    "        with self.assertRaises(AssertionError):\r\n",
    "            train_speck_distinguisher(num_epochs=0)\r\n",
    "  \r\n",
    "        # Invalid num_rounds\r\n",
    "        with self.assertRaises(AssertionError):\r\n",
    "            train_speck_distinguisher(num_epochs=200, num_rounds=0)\r\n",
    "        \r\n",
    "        # Invalid depth\r\n",
    "        with self.assertRaises(AssertionError):\r\n",
    "            train_speck_distinguisher(num_epochs=200, depth=0)\r\n",
    "        \r\n",
    "        # Invalid num_blocks\r\n",
    "        with self.assertRaises(AssertionError):\r\n",
    "            train_speck_distinguisher(num_epochs=200, num_blocks=1)\r\n",
    "            \r\n",
    "        # Invalid num_blocks\r\n",
    "        with self.assertRaises(AssertionError):\r\n",
    "            train_speck_distinguisher(num_epochs=200, num_blocks=10)\r\n",
    "            \r\n",
    "        # Invalid diffa: not tuple\r\n",
    "        with self.assertRaises(AssertionError):\r\n",
    "            train_speck_distinguisher(num_epochs=200, diffa=10)\r\n",
    "\r\n",
    "        # Invalid diffa: not hexadecimal\r\n",
    "        with self.assertRaises(SyntaxError):\r\n",
    "            eval('train_speck_distinguisher(num_epochs=200, diffa=(0x00fz,0))')\r\n",
    "\r\n",
    "        # Invalid diffb: not tuple\r\n",
    "        with self.assertRaises(AssertionError):\r\n",
    "            train_speck_distinguisher(num_epochs=200, diffb=0)\r\n",
    "                \r\n",
    "        # Invalid diffb: not hexadecimal\r\n",
    "        with self.assertRaises(SyntaxError):\r\n",
    "            eval('train_speck_distinguisher(num_epochs=200, diffb=(0x0040,0xfffg))')\r\n",
    "            \r\n",
    "        \r\n",
    "if __name__ == '__main__': \r\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False, verbosity=2)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}