{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eval.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrusRD34ltSL"
      },
      "source": [
        "Mount your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzu6t5EKZGyQ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpeTW4zT-XfM"
      },
      "source": [
        "# MODIFY HERE TO YOUR PATH IN GOOGLE DRIVE\n",
        "%cd /content/gdrive/MyDrive/CryptoML"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytDWS2SLlwfN"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9trkzwXl3Un"
      },
      "source": [
        "Install SHAP "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdjcptLg-wwM"
      },
      "source": [
        "!pip install shap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk2SSbxqnFZJ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3373hF2SnGV-"
      },
      "source": [
        "Execute the functions to evaluate our models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAtM9RY1-mqc"
      },
      "source": [
        "import speck as sp\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "def create_testing_data(num_of_plaintexts, num_rounds):\n",
        "  '''\n",
        "  This function generates a set of testing data\n",
        "\n",
        "  Inputs:\n",
        "    - num_of_plaintexts: Number of plaintexts / num_blocks you used to train your model\n",
        "    - num_rounds: Number of rounds of Speck / num_rounds you used to train your model\n",
        "\n",
        "  Outputs:\n",
        "    - X: Binary array of ciphertexts\n",
        "    - Y: Relationship of ciphertexts\n",
        "    - Xr: Binary array of ciphertexts having real differences\n",
        "    - Yr: Relationship of ciphertexts having real differences\n",
        "\n",
        "  '''\n",
        "  assert num_of_plaintexts in [2, 4]\n",
        "  assert num_rounds > 0\n",
        "\n",
        "  if num_of_plaintexts == 2:\n",
        "    X, Y = sp.make_train_data_2pt(10**6, num_rounds)\n",
        "    Xr, Yr = sp.real_differences_data_2pt(10**6, num_rounds)\n",
        "\n",
        "  else:\n",
        "    X, Y = sp.make_train_data_4pt(10**6, num_rounds)\n",
        "    Xr, Yr = sp.real_differences_data_4pt(10**6, num_rounds)\n",
        "\n",
        "  return X, Y, Xr, Yr\n",
        "\n",
        "\n",
        "def get_inputs(num_of_plaintexts, num_rounds, num_of_samples, model_name):\n",
        "  '''\n",
        "  This function is used to ensure all of the parameters modified by users have no error\n",
        "\n",
        "  Inputs: \n",
        "    - num_of_plaintexts: Number of plaintexts\n",
        "    - num_rounds: Number of rounds of Speck\n",
        "    - num_of_samples: Number of samples to visualise using SHAP\n",
        "    - model_name: File name of the saved model\n",
        "\n",
        "  Outputs:\n",
        "    - num_of_plaintexts: Number of plaintexts\n",
        "    - num_rounds: Number of rounds of Speck\n",
        "    - num_of_samples: Number of samples to visualise using SHAP\n",
        "    - net: The model loaded from the file given\n",
        "\n",
        "  '''\n",
        "  assert num_of_plaintexts in [2,4]\n",
        "  assert num_rounds > 0\n",
        "  assert num_of_samples > 1\n",
        "  assert model_name[-3:] == \".h5\"\n",
        "\n",
        "  num_of_plaintexts = num_of_plaintexts\n",
        "  num_rounds = num_rounds\n",
        "  net = load_model('./models/' + model_name)\n",
        "  num_of_samples = num_of_samples\n",
        "\n",
        "  return num_of_plaintexts, num_rounds, num_of_samples, net\n",
        "\n",
        "\n",
        "def evaluate(net,X,Y):\n",
        "  '''\n",
        "  This function evaluate the model with testing data\n",
        "\n",
        "  Inputs:\n",
        "    - net: The model to evaluate\n",
        "    - X: Binary array of ciphertexts\n",
        "    - Y: Relationship of ciphertexts (0 or 1)\n",
        "\n",
        "  Outputs:\n",
        "  Accuracy, true positive rate, true negative rate and mean squared error of model will be printed\n",
        "  Percentage of random pairs with score higher than median of real pairs will also be printed\n",
        "\n",
        "  '''\n",
        "  Z = net.predict(X,batch_size=10000).flatten()\n",
        "  Zbin = (Z > 0.5)\n",
        "  diff = Y - Z \n",
        "  mse = np.mean(diff*diff)\n",
        "  n = len(Z) \n",
        "  n0 = np.sum(Y==0) \n",
        "  n1 = np.sum(Y==1)\n",
        "  acc = np.sum(Zbin == Y) / n\n",
        "  tpr = np.sum(Zbin[Y==1]) / n1\n",
        "  tnr = np.sum(Zbin[Y==0] == 0) / n0\n",
        "  mreal = np.median(Z[Y==1])\n",
        "  high_random = np.sum(Z[Y==0] > mreal) / n0\n",
        "  print(\"Accuracy: \", acc, \"TPR: \", tpr, \"TNR: \", tnr, \"MSE:\", mse)\n",
        "  print(\"Percentage of random pairs with score higher than median of real pairs:\", 100 * high_random)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUA73FMPlvyJ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6znzDxsuth4"
      },
      "source": [
        "Modify the parameters and run the cells to evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgzPd6ZA-4XT"
      },
      "source": [
        "'''\n",
        "Paramter description:\n",
        "  - num_of_plaintexts: Number of plaintexts\n",
        "  - num_rounds: Number of rounds of Speck\n",
        "  - num_of_samples: Number of samples to visualise using SHAP\n",
        "  - model_name: File name of the saved model\n",
        "\n",
        "'''\n",
        "\n",
        "# MODIFY HERE                                                                     ↓             ↓                 ↓                     ↓\n",
        "num_of_plaintexts, num_rounds, num_of_samples, net = get_inputs(num_of_plaintexts=4, num_rounds=5, num_of_samples=10, model_name=\"best5depth10.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiWIHDaAvJ2L"
      },
      "source": [
        "import shap\n",
        "\n",
        "X, Y, Xr, Yr = create_testing_data(num_of_plaintexts, num_rounds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q8kuQO4_Bzi"
      },
      "source": [
        "print('Testing neural distinguishers against blocks in the ordinary real vs random setting')\n",
        "evaluate(net, X, Y)\n",
        "\n",
        "shap.initjs()\n",
        "explainer = shap.KernelExplainer(net.predict, X[:num_of_samples])\n",
        "shap_values = explainer.shap_values(X[:num_of_samples])\n",
        "shap.force_plot(explainer.expected_value[0], shap_values[0], X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6hoseLt_DF-"
      },
      "source": [
        "print('Testing real differences setting now.')\n",
        "evaluate(net, Xr, Yr)\n",
        "\n",
        "shap.initjs()\n",
        "explainer = shap.KernelExplainer(net.predict, Xr[:num_of_samples])\n",
        "shap_values = explainer.shap_values(Xr[:num_of_samples])\n",
        "shap.force_plot(explainer.expected_value[0], shap_values[0], Xr)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}