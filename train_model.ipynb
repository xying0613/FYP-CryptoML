{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGC1mBY6jtQx"
      },
      "source": [
        "Mount your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUdrKjcXDDmd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OO2fAyuDFRL"
      },
      "source": [
        "# MODIFY HERE TO YOUR PATH IN GOOGLE DRIVE\n",
        "%cd /content/gdrive/MyDrive/CryptoML"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEYLOo0_kuYM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xukHm7xtklI0"
      },
      "source": [
        "Execute the functions to train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhpoMEFWXywa"
      },
      "source": [
        "import speck as sp\n",
        "import numpy as np\n",
        "from pickle import dump\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Input, Reshape, Permute, Add, Flatten, BatchNormalization, Activation\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "bs = 5000;\n",
        "dir = './models/'\n",
        "\n",
        "def cyclic_lr(num_epochs, high_lr, low_lr):\n",
        "  '''\n",
        "  This function is to get the learning rate according to the number of epochs\n",
        "  and ensure the learning rate is within the range.\n",
        "\n",
        "  Inputs:\n",
        "    - num_epochs: Number of epochs\n",
        "    - high_lr: Highest learning rate\n",
        "    - low_lr: Lowest learning rate\n",
        "\n",
        "  Output:\n",
        "  The learning rate of the corresponding number of epochs will be returned\n",
        "\n",
        "  '''\n",
        "  res = lambda i: low_lr + ((num_epochs-1) - i % num_epochs)/(num_epochs-1) * (high_lr - low_lr)\n",
        "  return res\n",
        "\n",
        "\n",
        "def make_checkpoint(datei):\n",
        "  '''\n",
        "  This function makes a checkpoint of the model. \n",
        "\n",
        "  Input: datai is the directory where we wish to save the model\n",
        "  Output: A saved Keras model when the validation loss is at its least\n",
        "\n",
        "  '''\n",
        "  assert datei[:9] == \"./models/\"\n",
        "  assert datei[-3:] == \".h5\"\n",
        "    \n",
        "  res = ModelCheckpoint(datei, monitor='val_loss', save_best_only = True)\n",
        "  return res\n",
        "\n",
        "\n",
        "def make_resnet(num_blocks=2, num_filters=32, num_outputs=1, d1=64, d2=64, word_size=16, ks=3, depth=5, reg_param=0.0001, final_activation='sigmoid'):\n",
        "  '''\n",
        "  This function makes residual tower of convolutional blocks.\n",
        "  \n",
        "  Inputs:\n",
        "    - num_blocks: Number of plaintexts\n",
        "    - num_filters: Number of filters in the Conv1D layers\n",
        "    - num_outputs: Number of outputs for the final prediction (0 or 1 in this case)\n",
        "    - d1: Units in the first Dense layer \n",
        "    - d2: Units in the second Dense layer\n",
        "    - word_size: Word size which will affect the shape of Input layer\n",
        "    - ks: Kernel size for the Conv1D layers in the residual blocks\n",
        "    - depth: The number of residual blocks\n",
        "    - reg_param: Parameter for regularizers\n",
        "    - final_activation: The activation function in the final Dense layer\n",
        "\n",
        "  Output: \n",
        "  A Keras model\n",
        "\n",
        "  '''\n",
        "  assert num_outputs == 1\n",
        "  assert num_blocks in [2,4]\n",
        "\n",
        "  # Input and preprocessing layers\n",
        "  inp = Input(shape=(num_blocks * word_size * 2))\n",
        "  rs = Reshape((2 * num_blocks, word_size))(inp)\n",
        "  perm = Permute((2,1))(rs)\n",
        "  \n",
        "  # Add a single residual layer that will expand the data to num_filters channels\n",
        "  # This is a bit-sliced layer\n",
        "  conv0 = Conv1D(num_filters, kernel_size=1, padding='same', kernel_regularizer=l2(reg_param))(perm)\n",
        "  conv0 = BatchNormalization()(conv0)\n",
        "  conv0 = Activation('relu')(conv0)\n",
        "\n",
        "  # Add residual blocks\n",
        "  shortcut = conv0\n",
        "  for _ in range(depth):\n",
        "    conv1 = Conv1D(num_filters, kernel_size=ks, padding='same', kernel_regularizer=l2(reg_param))(shortcut)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    conv2 = Conv1D(num_filters, kernel_size=ks, padding='same',kernel_regularizer=l2(reg_param))(conv1)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Activation('relu')(conv2)\n",
        "    shortcut = Add()([shortcut, conv2])\n",
        "\n",
        "  # Add prediction head\n",
        "  flat1 = Flatten()(shortcut)\n",
        "  dense1 = Dense(d1,kernel_regularizer=l2(reg_param))(flat1)\n",
        "  dense1 = BatchNormalization()(dense1)\n",
        "  dense1 = Activation('relu')(dense1)\n",
        "  dense2 = Dense(d2, kernel_regularizer=l2(reg_param))(dense1)\n",
        "  dense2 = BatchNormalization()(dense2)\n",
        "  dense2 = Activation('relu')(dense2)\n",
        "  out = Dense(num_outputs, activation=final_activation, kernel_regularizer=l2(reg_param))(dense2)\n",
        "  model = Model(inputs=inp, outputs=out)\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def train_speck_distinguisher(num_epochs, num_rounds=7, depth=1, num_blocks=2, diffa=(0x0040,0), diffb=(0x0020,0)):\n",
        "  '''\n",
        "  This function trains the model and saves it to the models folder.\n",
        "\n",
        "  Inputs:\n",
        "    - num_epochs: Number of epochs you want to train\n",
        "    - num_rounds: Number of rounds of the Speck\n",
        "    - depth: The number of residual blocks\n",
        "    - num_blocks: Number of plaintexts\n",
        "    - diffa: Bit difference 1\n",
        "    - diffb: Bit difference 2 (if training with 4 ciphertexts)\n",
        "\n",
        "  Outputs:\n",
        "    - net: Network\n",
        "    - h: The trained model\n",
        "    \n",
        "  '''\n",
        "  assert num_epochs > 0\n",
        "  assert num_rounds > 0\n",
        "  assert depth > 0\n",
        "  assert num_blocks in [2, 4]\n",
        "  assert type(diffa) is tuple and type(diffb) is tuple\n",
        "\n",
        "  # Create the network\n",
        "  net = make_resnet(num_blocks=num_blocks, depth=depth, reg_param=10**-5)\n",
        "  net.compile(optimizer='adam',loss='mse',metrics=['acc'])\n",
        "\n",
        "  # Generate training and validation data\n",
        "  if num_blocks == 2:\n",
        "    X, Y = sp.make_train_data_2pt(10**7, num_rounds, diff=diffa)\n",
        "    X_eval, Y_eval = sp.make_train_data_2pt(10**6, num_rounds, diff=diffa)\n",
        "  \n",
        "  else:\n",
        "    X, Y = sp.make_train_data_4pt(10**7, num_rounds, diffa=diffa, diffb=diffb)\n",
        "    X_eval, Y_eval = sp.make_train_data_4pt(10**6, num_rounds, diffa=diffa, diffb=diffb)\n",
        "\n",
        "  # Set up model checkpoint\n",
        "  check = make_checkpoint(dir+'best'+str(num_rounds)+'depth'+str(depth)+'.h5')\n",
        "\n",
        "  # Create learnrate schedule\n",
        "  lr = LearningRateScheduler(cyclic_lr(10,0.002, 0.0001))\n",
        "\n",
        "  # Train and evaluate\n",
        "  h = net.fit(X,Y,epochs=num_epochs,batch_size=bs,validation_data=(X_eval, Y_eval), callbacks=[lr,check])\n",
        "  np.save(dir+'h'+str(num_rounds)+'r_depth'+str(depth)+'.npy', h.history['val_acc'])\n",
        "  np.save(dir+'h'+str(num_rounds)+'r_depth'+str(depth)+'.npy', h.history['val_loss'])\n",
        "  dump(h.history,open(dir+'hist'+str(num_rounds)+'r_depth'+str(depth)+'.p','wb'))\n",
        "  print(\"Best validation accuracy: \", np.max(h.history['val_acc']))\n",
        "\n",
        "  return net, h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PI8HoFSkxSO"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6RjW4CjkyHn"
      },
      "source": [
        "Modify the parameters and run this cell to start training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kX49J7fDx4-"
      },
      "source": [
        "'''\n",
        "Parameter description: \n",
        "  - num_epochs: number of epochs, \n",
        "  - num_rounds: Number of rounds of the Speck\n",
        "  - depth: The number of residual blocks\n",
        "  - num_blocks: Number of plaintexts\n",
        "  - diffa: Bit difference 1\n",
        "  - diffb: Bit difference 2 (if training with 4 ciphertexts)\n",
        "\n",
        "'''\n",
        "\n",
        "# MODIFY HERE:                       ↓             ↓        ↓             ↓            ↓                  ↓\n",
        "train_speck_distinguisher(num_epochs=1, num_rounds=5, depth=1, num_blocks=4, diffa=(0x0040,0), diffb=(0x0020,0))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}